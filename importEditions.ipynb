{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv, re, requests\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the data from local file\n",
    "#file = \"data/digEds_cat.csv\"\n",
    "#with open(file, 'r', encoding='utf-8') as data:\n",
    "    #reader = csv.reader(data)\n",
    "    #datalist = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fetch data directly from github\n",
    "# see http://stackoverflow.com/questions/35371043/use-python-requests-to-download-csv\n",
    "url = 'https://raw.githubusercontent.com/gfranzini/digEds_cat/master/digEds_cat.csv'\n",
    "with requests.Session() as s:\n",
    "    download = s.get(url)\n",
    "    decoded_content = download.content.decode('utf-8')\n",
    "    cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "    datalist = list(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#replace all empty fields with \"no information provided\" and store result in list called cleaned_data\n",
    "cleaned_data = []\n",
    "for row in datalist:\n",
    "    cleaned_row = []\n",
    "    for cell in row:\n",
    "        if str(cell) == \"\":\n",
    "            cell = re.sub(\"\", \"no information provided\", cell)\n",
    "            cleaned_row.append(cell)\n",
    "        else:\n",
    "            cleaned_row.append(cell)\n",
    "    cleaned_data.append(cleaned_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\digital-editions\\lib\\site-packages\\django\\db\\backends\\mysql\\base.py:112: Warning: Data truncated for column 'key_or_ocr' at row 1\n",
      "  return self.cursor.execute(query, args)\n",
      "\n",
      "WARNING:py.warnings:C:\\Anaconda3\\envs\\digital-editions\\lib\\site-packages\\django\\db\\backends\\mysql\\base.py:112: Warning: Data truncated for column 'key_or_ocr' at row 1\n",
      "  return self.cursor.execute(query, args)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BOOLEAN_CHOICES = {\n",
    "    \"1\": \"yes\",\n",
    "    \"0\": \"no\",\n",
    "    \"no information provided\": \"no information provided\",\n",
    "    \"trial\": \"no\",\n",
    "    \"forthcoming\": \"no\",\n",
    "    \"download book\": \"no\",\n",
    "    \"N/A\": \"no\",\n",
    "    \"0.5\": \"no\",\n",
    "    \"0,5\": \"no\",\n",
    "    \"PDF will be available\": \"no\"\n",
    "}\n",
    "\n",
    "for row in cleaned_data:\n",
    "    if row[3] != \"\" and row[0] != \"Historical Period\":\n",
    "        temp_per, _ = Period.objects.get_or_create(name=row[0])\n",
    "        temp_ed, _ = Edition.objects.get_or_create(url=row[3])\n",
    "        temp_ed.name = row[2]\n",
    "        temp_ed.scholarly = BOOLEAN_CHOICES[str(row[4])]\n",
    "        temp_ed.digital = BOOLEAN_CHOICES[str(row[5])]\n",
    "        temp_ed.edition = BOOLEAN_CHOICES[str(row[6])]\n",
    "        if row[7] != \"\":\n",
    "            langs1 = row[7].split(\",\")\n",
    "            for x in langs1:\n",
    "                temp_lang_source, _ = Language.objects.get_or_create(iso_code=(x.strip().lower())[:3])\n",
    "                temp_ed.language.add(temp_lang_source)\n",
    "        temp_ed.writing_support = row[8]\n",
    "        if row[9] != \"\":\n",
    "            start_date = re.match(\"\\d{4}\", row[9])\n",
    "            if start_date:\n",
    "                start_date = datetime.strptime(start_date.group(), '%Y')\n",
    "                temp_ed.begin_date = start_date\n",
    "        if row[10] != \"\":\n",
    "            end_date = re.match(\"\\d{4}\", row[10])\n",
    "            if end_date:\n",
    "                end_date = datetime.strptime(end_date.group(), '%Y')\n",
    "                temp_ed.end_date = end_date\n",
    "        for pers in row[11].split(\";\"):\n",
    "            pers_temp, _ = Person.objects.get_or_create(name = pers.strip())\n",
    "            temp_ed.manager.add(pers_temp)\n",
    "        for inst in row[12].split(\";\"):\n",
    "            inst_temp, _ = Institution.objects.get_or_create(name = inst.strip())\n",
    "            temp_ed.institution.add(inst_temp)\n",
    "        temp_ed.audience = str(row[13])\n",
    "        temp_ed.philological_statement = str(row[14])\n",
    "        temp_ed.textual_variance = str(row[15])\n",
    "        temp_ed.value_witnesses = str(row[16])\n",
    "        temp_ed.tei_transcription = str(row[17]).strip()\n",
    "        temp_ed.download = str(row[18]).strip()\n",
    "        temp_ed.images = BOOLEAN_CHOICES[str(row[19])]\n",
    "        temp_ed.zoom_images = BOOLEAN_CHOICES[str(row[20])]\n",
    "        temp_ed.image_manipulation = BOOLEAN_CHOICES[str(row[21])]\n",
    "        temp_ed.text_image = BOOLEAN_CHOICES[str(row[22])]\n",
    "        #source text translation (row[24]) not imported due to messy data\n",
    "        if row[24] != \"\":\n",
    "            langs = row[24].split(\";\")\n",
    "            for y in langs:\n",
    "                temp_lang_website, _ = Language.objects.get_or_create(iso_code=(y.strip().lower())[:3])\n",
    "                temp_ed.website_language.add(temp_lang_website)\n",
    "        temp_ed.glossary = BOOLEAN_CHOICES[str(row[25])]\n",
    "        temp_ed.indices = BOOLEAN_CHOICES[str(row[26])]\n",
    "        temp_ed.search = BOOLEAN_CHOICES[str(row[27])]\n",
    "        temp_ed.advanced_search = BOOLEAN_CHOICES[str(row[28])]\n",
    "        temp_ed.cc_license = BOOLEAN_CHOICES[str(row[29])]\n",
    "        temp_ed.open_source = row[30]\n",
    "        temp_ed.key_or_ocr = str(row[37])\n",
    "        temp_ed.print_friendly = BOOLEAN_CHOICES[str(row[38])]\n",
    "        temp_ed.infrastructure = str(row[45])\n",
    "        temp_ed.api = str(row[32])\n",
    "        temp_ed.historical_period.add(temp_per)        \n",
    "        temp_ed.save()\n",
    "        #print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n",
      "232\n",
      "255\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "# count number of objects\n",
    "# be aware: running the script importInstitutions creates 124 institutions\n",
    "# but after running this script, there are 241 institutions in the database\n",
    "# running this script before importInstitutioins leads to 226 instituions\n",
    "eds = Edition.objects.all()\n",
    "print(len(eds))\n",
    "persons = Person.objects.all()\n",
    "print(len(persons))\n",
    "inst = Institution.objects.all()\n",
    "print(len(inst))\n",
    "print(len(Language.objects.all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in Edition.objects.all():\n",
    "    x.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
